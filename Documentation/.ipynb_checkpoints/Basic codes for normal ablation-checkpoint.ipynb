{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "killing-score",
   "metadata": {},
   "source": [
    "## Basic codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-value",
   "metadata": {},
   "source": [
    "The purpose of this document is to give a condensed presentation of the various codes used to implement the ablation model, uniform or not, in one or two dimensions. For the sake of brevity, no examples will be shown here, just the raw codes, with as much commentary as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-registrar",
   "metadata": {},
   "source": [
    "### 1D uniform ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-watson",
   "metadata": {},
   "source": [
    "#### First version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-australian",
   "metadata": {},
   "source": [
    "Simplest implementation of the model. The interface is represented by a set of points $(x,z)$. The algorithm takes as input the list of abscissas ($\\textit{xx}$) and the list of ordinates ($\\textit{zz}$), as well as the distance $\\textit{l}$ by which the interface should be eroded. It returns the list of abscissas and the list of ordinates corresponding to the interface obtained after erosion.\n",
    "\n",
    "First, the algorithm calculates the normal vector, pointing downwards, at each point of the interface. It then propagates each point of the interface by a distance $\\textit{l}$ along this normal vector to obtain the new interface. However, if we stop there, we see \"loops\" or \"swallow-tails\" appear at the interface points where the radius of curvature is less than $\\textit{l}$. These loops need to be removed to obtain the 'physical' interface: that's what the antepenultimate line of code does. The idea is that deleting these loops means deleting all the points located at a distance strictly less than $\\textit{l}$ from the initial interface (i.e. located at a distance strictly less than $\\textit{l}$ from at least one of the points on the initial interface).\n",
    "\n",
    "In concrete terms, $\\textit{distance_matrix(new_coord, ex_coord)}$ returns a matrix $D_{ij}$ containing the distances between each point on the new interface (index $i$) and each point on the old interface (index $j$). $\\textit{distance_matrix(new_coord,ex_coord)<l*se}$ is a matrix whose index $D^{'}_{ij}$ takes the value $\\textit{True}$ if the distance between the point $i$ of the new interface and the point $j$ of the old interface are closer than $\\textit{l}\\cdot \\textit{se}$, $\\textit{False}$ otherwise. The distances are compared to $\\textit{l}\\cdot \\textit{se}$ rather than $\\textit{l}$ for reasons of rounding: if you don't do this, the code sometimes considers that a point on the new interface is strictly closer than $\\textit{l}$ to the point on the old interface from which it originated (even though it is theoretically at a distance equal to $\\textit{l}$, since this is how it was constructed); this leads to the deletion of the said point. Taking $\\textit{se}$ very close to 1 but strictly less than 1 avoids this inconvenience. Next, $\\textit{np.unique(np.asarray((distance_matrix(new_coord,ex_coord)<l*se).nonzero()[0])}$ is a list containing the index $i$ if there is at least one $j$ such that $D^{'}_{ij}$ has the value $\\textit{True}$. Finally, $\\textit{np.delete(new_coord,np.unique(np.asarray((distance_matrix(new_coord,ex_coord)<l*se).nonzero()[0])),axis=0)}$ deletes all the points whose indices are in the previous list. In this way, the loops have been eliminated and the algorithm ends up returning the list of abscissas and the list of ordinates of the new eroded interface.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "military-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "se=0.999999\n",
    "def erod(xx,zz,l):\n",
    "    #points obtained by moving by a distance l along the normal\n",
    "    gradvec=np.array([np.gradient(zz),-np.gradient(xx)])#computation of a normal vector\n",
    "    vecn=l*gradvec/np.linalg.norm(gradvec,axis=0)#normal vector of norm l\n",
    "    xxprop=xx+vecn[0,:]\n",
    "    zzprop=zz+vecn[1,:]#new points obtained     \n",
    "    #keep only points which are at a distance farther than l from the initial curve\n",
    "    new_coord=np.transpose(np.array([xxprop,zzprop]))\n",
    "    ex_coord=np.transpose(np.array([xx,zz]))\n",
    "    cleaned_new_coord=np.delete(new_coord,np.unique(np.asarray((distance_matrix(new_coord,ex_coord)<l*se).nonzero()[0])),axis=0)\n",
    "    final_xx,final_zz=cleaned_new_coord[:,0],cleaned_new_coord[:,1]\n",
    "    return final_xx, final_zz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-obligation",
   "metadata": {},
   "source": [
    "#### Improved version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-final",
   "metadata": {},
   "source": [
    "The version of the algorithm presented above has the disadvantage of being fairly costly in terms of calculation time, particularly because of the $\\textit{distance_matrix}$ which quickly becomes cumbersome to calculate as the number of interface points increases. However, this matrix calculates many unnecessary distances: it is clear that it is not necessary to calculate the distance between the leftmost point of the initial interface and the rightmost point of the eroded interface to know that it is greater than $\\textit{l}$. The version presented below thus improves the algorithm by calculating, for a point on the new interface, only its distance from the $N_v$ neighbours to the right and left of the point on the initial interface from which it originated. We have therefore replaced the calculation of $\\textit{distance_matrix}$, of size $n \\cdot n$ with $n$ the number of points, by the calculation of the matrix $\\textit{distance_neighbours}$ of size $n \\cdot N_v$.\n",
    "\n",
    "$N_v$ is a parameter that must be chosen carefully. If $N_v$ is too small, you run the risk of keeping points that should be removed (points belonging to the loops we talked about earlier); but if $N_v$ is too big, then the code is too slow. A good way of doing this (in my opinion) is to choose $N_v$ as follows: $N_v=2l/\\mathrm{dx}$ where $\\mathrm{dx}$ is the distance along the x axis between two successive points on the initial interface (this is possible if $\\mathrm{dx}$ is constant). By determining $N_v$ in this way, we can be sure to remove all the points that need to be removed (see triangular inequality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "relative-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_neighbours(ex,new,n):\n",
    "    distmat=np.zeros((2*n+1,np.shape(new)[1]))\n",
    "    for k in range(-n,n+1):\n",
    "        ex_rollk=np.roll(ex,k)\n",
    "        distmat[n+k]=np.sqrt(np.sum((new-ex_rollk)**2,axis=0))\n",
    "    return np.concatenate((distmat[:n],distmat[n+1:]),axis=0)   \n",
    "\n",
    "def erod_improved(xx,zz,l,n):\n",
    "    #points obtain by moving by a distance l along the normal\n",
    "    gradvec=np.array([np.gradient(zz),-np.gradient(xx)])# Calcul du vecteur normal initial.\n",
    "    vecn=l*gradvec/np.linalg.norm(gradvec,axis=0)\n",
    "    xxprop=xx+vecn[0,:]\n",
    "    zzprop=zz+vecn[1,:]    \n",
    "    #keep only points which are at a distance farther than l from the initial curve\n",
    "    new_coord=np.array([xxprop,zzprop])\n",
    "    ex_coord=np.array([xx,zz])\n",
    "    cleaned_new_coord=np.delete(new_coord,np.unique((distance_neighbours(ex_coord,new_coord,n)<l*se).nonzero()[1]),axis=1)\n",
    "    final_xx,final_zz=cleaned_new_coord[0,:],cleaned_new_coord[1,:]\n",
    "    return final_xx, final_zz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-clause",
   "metadata": {},
   "source": [
    "### 1D non-uniform ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-stupid",
   "metadata": {},
   "source": [
    "The algorithm below is a generalisation of the previous algorithm. Ablation is no longer necessarily uniform. The erosion distance, which was previously the same everywhere (it was denoted $\\textit{l}$), is now a priori different for each point ($\\textit{l}=\\textit{l(i)}$). In concrete terms, instead of multiplying the list of normal vectors by a scalar $\\textit{l}$, we multiply it term by term with the list $\\textit{l} \\cdot f_{er}(xx,zz,e)$, where $f_{er}(xx,zz,e)$ is a function which assigns an erosion distance to each point on the interface, depending a priori on the shape of the interface and on an additional parameter $pp$. This function is entered as code input by the user, so you can imagine all sorts of more or less twisted things.\n",
    "\n",
    "The removal of loops in the second part of the code is slightly more subtle than in the uniform case. To keep a point, it is no longer enough to check that it is strictly further than $\\textit{l}$ from the initial interface; it must be further than $l(i)$ from each point $i$ of the initial interface, which requires the code to be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erod_non_uniform_improved(xx,zz,l,f_er,pp,n):\n",
    "    ff=f_er(xx,zz,pp)\n",
    "    #points obtain by moving by a distance l along the normal\n",
    "    gradvec=np.array([np.gradient(zz),-np.gradient(xx)])\n",
    "    vecn=l*ff*gradvec/np.linalg.norm(gradvec,axis=0)\n",
    "    xxprop=xx+vecn[0,:]\n",
    "    zzprop=zz+vecn[1,:]    \n",
    "    #keep only points which are at a distance farther than l from the initial curve\n",
    "    new_coord=np.array([xxprop,zzprop])\n",
    "    ex_coord=np.array([xx,zz])\n",
    "    f_er_mat=np.array([np.concatenate((np.roll(ff,n-i)[:n],np.roll(ff,n-i)[n+1:2*n+1])) for i in range(len(xxprop))]).transpose()\n",
    "    cleaned_new_coord=np.delete(new_coord,np.unique((distance_neighbours(ex_coord,new_coord,n)<l*se*f_er_mat).nonzero()[1]),axis=1)\n",
    "    final_xx,final_zz=cleaned_new_coord[0,:],cleaned_new_coord[1,:]\n",
    "    return final_xx, final_zz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-polyester",
   "metadata": {},
   "source": [
    "### 2D uniform and non-uniform ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-johnson",
   "metadata": {},
   "source": [
    "The algorithms below are extensions of the 1D ablation algorithm to 2D: the interface is now a surface ($z(x,y)$). The principle of the algorithm is broadly similar to the principle of the $\\textit{erod_improved}$ function. To remove the loops, we look at the distance between each point on the new interface and the neighbours ($nx$ in the x direction, $ny$ in the y direction) of the point on the initial interface from which that point originated. All these distances are contained in the three-dimensional array returned by the function $\\textit{distance_neighbours_2d}$. \n",
    "\n",
    "In concrete terms, the initial surface is a set of points located on a grid, which can be reconstructed from the two lists $xx$ and $yy$ corresponding to the coordinates of the grid points in the $x$ and $y$ directions respectively. The algorithm takes as input these two lists and the matrix $zz$ corresponding to the heights of the points on the said grid. It also takes as input the erosion distance $l$ and the number of neighbours $nx$ and $ny$ on which to make the comparison. \n",
    "\n",
    "At the end, the code returns the matrix $zer$ corresponding to the heights of the eroded interface on the same grid as the input grid; to do this, it performs a Delaunay interpolation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indonesian-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_neighbours_2d(ex,new,dx,dy,nx,ny):\n",
    "    distmat=np.zeros((2*nx+1,2*ny+1,len(ex)))\n",
    "    for k in range(-nx,nx+1):\n",
    "        for j in range(-ny,ny+1):\n",
    "            ex_roll_kj=np.roll(ex,-dx*j-k,axis=0)\n",
    "            distmat[nx+k,ny+j]=np.sqrt(np.sum((new-ex_roll_kj)**2,axis=1))\n",
    "    return distmat\n",
    "\n",
    "def propag_neighbours_2d(ff,lx,ly,nx,ny):\n",
    "    neighbmat=np.zeros((2*nx+1,2*ny+1,len(ff)))\n",
    "    for k in range(-nx,nx+1):\n",
    "        for j in range(-ny,ny+1):\n",
    "            ff_roll_kj=np.roll(ff,-lx*j-k)\n",
    "            voismat[nx+k,ny+j]=ff_roll_kj\n",
    "    return neighbmat   \n",
    "\n",
    "def erod_improved_2d(xx,yy,zz,nx,ny,l):\n",
    "    #initialization\n",
    "    dx,dy=len(xx),len(yy)\n",
    "    XX,YY=np.meshgrid(xx,yy)\n",
    "    #points obtain by moving by a distance l along the normal\n",
    "    gradvec=np.append(np.gradient(zz.transpose(),xx,yy),[0*zzt-1],axis=0)#normal vector\n",
    "    vecn=l*gradvec/np.linalg.norm(gradvec,axis=0)\n",
    "    xxprop=XX+vecn[0,:].transpose()\n",
    "    yyprop=YY+vecn[1,:].transpose()\n",
    "    zzprop=zz+vecn[2,:].transpose()\n",
    "    #keep only points which are at a distance farther than l from the initial curve\n",
    "    new_coord=np.transpose(np.array([xxprop.flatten(),yyprop.flatten(),zzprop.flatten()]))\n",
    "    ex_coord=np.transpose(np.array([XX.flatten(),YY.flatten(),zz.flatten()]))\n",
    "    cleaned_new_coord=np.delete(new_coord,np.unique((distance_neighbours_2d(ex_coord,new_coord,dx,dy,nx,ny)<l*se).nonzero()[2]),axis=0)\n",
    "    #return points on a regular grid by interpolating\n",
    "    interpolator = tri.LinearTriInterpolator(tri.Triangulation(cleaned_new_coord[:,0],cleaned_new_coord[:,1]), cleaned_new_coord[:,2])\n",
    "    return interpolator(XX, YY)\n",
    "\n",
    "def erod_nonuniform_improved_2d(xx,yy,zz,nx,ny,l,fer,pp):\n",
    "    #initialization\n",
    "    lx,ly=len(xx),len(yy)\n",
    "    XX,YY=np.meshgrid(xx,yy)\n",
    "    #points obtain by moving by a distance l along the normal\n",
    "    gradvec=np.append(np.gradient(zz.transpose(),xx,yy),[0*zz.transpose()-1],axis=0)#normal vector \n",
    "    vecn=l*fer(XX,YY,zz,pp).transpose()*gradvec/np.linalg.norm(gradvec,axis=0)\n",
    "    xxprop=XX+vecn[0,:].transpose()\n",
    "    yyprop=YY+vecn[1,:].transpose()\n",
    "    zzprop=zz+vecn[2,:].transpose()\n",
    "    #keep only points which are at a distance farther than l from the initial curve\n",
    "    new_coord=np.transpose(np.array([xxprop.flatten(),yyprop.flatten(),zzprop.flatten()]))\n",
    "    ex_coord=np.transpose(np.array([XX.flatten(),YY.flatten(),zz.flatten()]))\n",
    "    ff=fer(XX,YY,zz,pp).flatten()\n",
    "    cleaned_new_coord=np.delete(new_coord,np.unique((distance_neighbours_2d(ex_coord,new_coord,lx,ly,nx,ny)<l*se*propag_neighbours_2d(ff,lx,ly,nx,ny)).nonzero()[2]),axis=0)\n",
    "    #return points on a regular grid by interpolating\n",
    "    interpolator = tri.LinearTriInterpolator(tri.Triangulation(cleaned_new_coord[:,0],cleaned_new_coord[:,1]), cleaned_new_coord[:,2])\n",
    "    return interpolator(XX, YY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
